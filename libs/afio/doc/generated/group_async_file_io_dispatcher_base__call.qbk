[/============================================================================
  Boost.AFIO

  Use, modification and distribution is subject to the Boost Software License,
  Version 1.0. (See accompanying file LICENSE_1_0.txt or copy at
  http://www.boost.org/LICENSE_1_0.txt)
=============================================================================/]


[/ Generated by doxygen_xml2qbk 1.1.0, don't change, will be overwritten automatically]
[/ Generated from doxy/doxygen_output/xml\group__async__file__io__dispatcher__base____call.xml]
[section:call_2_batch_bound_functions call (batch bound functions)]

'''<indexterm><primary>call</primary></indexterm>'''
Schedule a batch of asynchronous invocations of the specified bound functions when their supplied preconditions complete. 

[heading Description]
This is effectively a convenience wrapper for [^`completion()`]. It creates a packaged\u005ftask matching the [^`completion_t`] handler specification and calls the specified arbitrary callable, always returning completion on exit.

[heading Synopsis]
``template<class R>
std::pair< std::vector< future< R > >, std::vector< async_io_op > > async_file_io_dispatcher_base::call(const std::vector< async_io_op > & ops, const std::vector< std::function< R()>> & callables)``

[heading Parameters]

[table
[[Type] [Concept] [Name] [Description] ]
[[class R] [A compiler deduced return type of the bound functions. ] [ - ] [Must be specified]]
[[const std::vector< async_io_op > &] [] [ops] [A batch of precondition op handles. If default constructed, a precondition is null. ]]
[[const std::vector< std::function< R()>> &] [] [callables] [A batch of bound functions to call, returning R.]]
]


[heading Returns]
A pair with a batch of futures returning the result of each of the callables and a batch of op handles. 

[heading Header]
`#include <boost/afio/afio.hpp>`

[heading Complexity]Amortised O(N) to dispatch. Amortised O(N/threadpool) to complete.
[heading Exception Model]Propagates exceptions of any input preconditions with an errored state at the point of dispatch, and throws a `std::runtime_error` if any inputs have values which could not possibly be correct. Once a batch of input ops has been verified at the point of entry as not errored, you are guaranteed that the batch is atomically scheduled as a whole, unless a failure to allocate memory occurs.
[heading Example][call_example]


[endsect]

[section:call_1_batch_bound_functions_without_preconditions call (batch bound functions without preconditions)]

'''<indexterm><primary>call</primary></indexterm>'''
Schedule a batch of asynchronous invocations of the specified bound functions when their supplied preconditions complete. 

[heading Description]
This is effectively a convenience wrapper for [^`completion()`]. It creates a packaged\u005ftask matching the [^`completion_t`] handler specification and calls the specified arbitrary callable, always returning completion on exit. If you are seeing performance issues, using [^`completion()`] directly will have much less overhead.

[heading Synopsis]
``template<class R>
std::pair<std::vector<future<R> >, std::vector<async_io_op> > async_file_io_dispatcher_base::call(const std::vector< std::function< R()>> & callables)``

[heading Parameters]

[table
[[Type] [Concept] [Name] [Description] ]
[[class R] [A compiler deduced return type of the bound functions. ] [ - ] [Must be specified]]
[[const std::vector< std::function< R()>> &] [] [callables] [A batch of bound functions to call, returning R.]]
]


[heading Returns]
A pair with a batch of futures returning the result of each of the callables and a batch of op handles. 

[heading Header]
`#include <boost/afio/afio.hpp>`

[heading Complexity]Amortised O(N) to dispatch. Amortised O(N/threadpool) to complete.
[heading Exception Model]Propagates exceptions of any input preconditions with an errored state at the point of dispatch, and throws a `std::runtime_error` if any inputs have values which could not possibly be correct. Once a batch of input ops has been verified at the point of entry as not errored, you are guaranteed that the batch is atomically scheduled as a whole, unless a failure to allocate memory occurs.
[heading Example][call_example]


[endsect]

[section:call_3_single_unbound_callable call (single unbound callable)]

'''<indexterm><primary>call</primary></indexterm>'''
Schedule an asynchronous invocation of the specified unbound callable when its supplied precondition completes. Note that this function essentially calls [^`std::bind()`] on the callable and the args and passes it to the other call() overload taking a [^`std::function<>`]. You should therefore use [^`std::ref()`] etc. as appropriate. 

[heading Description]
This is effectively a convenience wrapper for [^`completion()`]. It creates a packaged\u005ftask matching the [^`completion_t`] handler specification and calls the specified arbitrary callable, always returning completion on exit. If you are seeing performance issues, using [^`completion()`] directly will have much less overhead.

[heading Synopsis]
``template<class C, class... Args>
std::pair< future< typename std::result_of< C(Args...)>::type >, async_io_op > async_file_io_dispatcher_base::call(const async_io_op & req, C callback, Args... args)``

[heading Parameters]

[table
[[Type] [Concept] [Name] [Description] ]
[[class C] [Any callable type. ] [ - ] [Must be specified]]
[[Args] [Any sequence of argument types. ] [ - ] [Must be specified]]
[[const async_io_op &] [] [req] [A precondition op handle. If default constructed, the precondition is null. ]]
[[C] [] [callback] [An unbound callable to call. ]]
[[Args...] [] [args] [An arbitrary sequence of arguments to bind to the callable.]]
]


[heading Returns]
A pair with a future returning the result of the callable and an op handle. 

[heading Header]
`#include <boost/afio/afio.hpp>`

[heading Complexity]Amortised O(1) to dispatch. Amortised O(1) to complete.
[heading Exception Model]Propagates exceptions of any input preconditions with an errored state at the point of dispatch, and throws a `std::runtime_error` if any inputs have values which could not possibly be correct. Once a batch of input ops has been verified at the point of entry as not errored, you are guaranteed that the batch is atomically scheduled as a whole, unless a failure to allocate memory occurs.
[heading Example][call_example]


[endsect]

